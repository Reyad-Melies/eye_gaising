{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebb02e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T14:57:34.549143Z",
     "start_time": "2023-02-15T14:57:34.543721Z"
    }
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    " \n",
    "# # Load the cascade\n",
    "# face_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "# # To capture video from webcam.\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# # To use a video file as input\n",
    "# # cap = cv2.VideoCapture('filename.mp4')\n",
    "# while True:\n",
    "#     # Read the frame\n",
    "#     _, img = cap.read()\n",
    "#     # Convert to grayscale\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     # Detect the faces\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "#     # Draw the rectangle around each face\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "#     # Display\n",
    "#     cv2.imshow('img', img)\n",
    "#     # Stop if escape key is pressed\n",
    "#     k = cv2.waitKey(30) & 0xff\n",
    "#     if k==27:\n",
    "#         break\n",
    "# # Release the VideoCapture object\n",
    "# cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a81875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7935b28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20915930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T11:53:18.769273Z",
     "start_time": "2023-02-21T11:53:18.764208Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Demonstration of the GazeTracking library.\n",
    "# Check the README.md for complete documentation.\n",
    "# \"\"\"\n",
    "\n",
    "# import cv2\n",
    "# from gaze_tracking import GazeTracking\n",
    "\n",
    "# gaze = GazeTracking()\n",
    "# webcam = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     # We get a new frame from the webcam\n",
    "#     _, frame = webcam.read()\n",
    "\n",
    "#     # We send this frame to GazeTracking to analyze it\n",
    "#     gaze.refresh(frame)\n",
    "\n",
    "#     frame = gaze.annotated_frame()\n",
    "#     text = \"\"\n",
    "\n",
    "#     if gaze.is_blinking():\n",
    "#         text = \"Blinking\"\n",
    "#     elif gaze.is_right():\n",
    "#         text = \"Looking right\"\n",
    "#     elif gaze.is_left():\n",
    "#         text = \"Looking left\"\n",
    "#     elif gaze.is_center():\n",
    "#         text = \"Looking center\"\n",
    "\n",
    "#     cv2.putText(frame, text, (90, 60), cv2.FONT_HERSHEY_DUPLEX, 1.6, (147, 58, 31), 2)\n",
    "\n",
    "#     left_pupil = gaze.pupil_left_coords()\n",
    "#     right_pupil = gaze.pupil_right_coords()\n",
    "#     cv2.putText(frame, \"Left pupil:  \" + str(left_pupil), (90, 130), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "#     cv2.putText(frame, \"Right pupil: \" + str(right_pupil), (90, 165), cv2.FONT_HERSHEY_DUPLEX, 0.9, (147, 58, 31), 1)\n",
    "\n",
    "#     cv2.imshow(\"Demo\", frame)\n",
    "\n",
    "#     if cv2.waitKey(1) == 27:\n",
    "#         break\n",
    "   \n",
    "# webcam.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b090e763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T10:59:53.342476Z",
     "start_time": "2022-05-24T10:59:53.309359Z"
    }
   },
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "# import os\n",
    "# import cv2\n",
    "# import dlib\n",
    "\n",
    "\n",
    "# class GazeTracking(object):\n",
    "#     \"\"\"\n",
    "#     This class tracks the user's gaze.\n",
    "#     It provides useful information like the position of the eyes\n",
    "#     and pupils and allows to know if the eyes are open or closed\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.frame = None\n",
    "#         self.eye_left = None\n",
    "#         self.eye_right = None\n",
    "#         self.calibration = Calibration()\n",
    "\n",
    "#         # _face_detector is used to detect faces\n",
    "#         self._face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "#         # _predictor is used to get facial landmarks of a given face\n",
    "#         cwd = os.path.abspath(os.path.dirname(__file__))\n",
    "#         model_path = os.path.abspath(os.path.join(cwd, \"trained_models/shape_predictor_68_face_landmarks.dat\"))\n",
    "#         self._predictor = dlib.shape_predictor(model_path)\n",
    "\n",
    "#     @property\n",
    "#     def pupils_located(self):\n",
    "#         \"\"\"Check that the pupils have been located\"\"\"\n",
    "#         try:\n",
    "#             int(self.eye_left.pupil.x)\n",
    "#             int(self.eye_left.pupil.y)\n",
    "#             int(self.eye_right.pupil.x)\n",
    "#             int(self.eye_right.pupil.y)\n",
    "#             return True\n",
    "#         except Exception:\n",
    "#             return False\n",
    "\n",
    "#     def _analyze(self):\n",
    "#         \"\"\"Detects the face and initialize Eye objects\"\"\"\n",
    "#         frame = cv2.cvtColor(self.frame, cv2.COLOR_BGR2GRAY)\n",
    "#         faces = self._face_detector(frame)\n",
    "\n",
    "#         try:\n",
    "#             landmarks = self._predictor(frame, faces[0])\n",
    "#             self.eye_left = Eye(frame, landmarks, 0, self.calibration)\n",
    "#             self.eye_right = Eye(frame, landmarks, 1, self.calibration)\n",
    "\n",
    "#         except IndexError:\n",
    "#             self.eye_left = None\n",
    "#             self.eye_right = None\n",
    "\n",
    "#     def refresh(self, frame):\n",
    "#         \"\"\"Refreshes the frame and analyzes it.\n",
    "\n",
    "#         Arguments:\n",
    "#             frame (numpy.ndarray): The frame to analyze\n",
    "#         \"\"\"\n",
    "#         self.frame = frame\n",
    "#         self._analyze()\n",
    "\n",
    "#     def pupil_left_coords(self):\n",
    "#         \"\"\"Returns the coordinates of the left pupil\"\"\"\n",
    "#         if self.pupils_located:\n",
    "#             x = self.eye_left.origin[0] + self.eye_left.pupil.x\n",
    "#             y = self.eye_left.origin[1] + self.eye_left.pupil.y\n",
    "#             return (x, y)\n",
    "\n",
    "#     def pupil_right_coords(self):\n",
    "#         \"\"\"Returns the coordinates of the right pupil\"\"\"\n",
    "#         if self.pupils_located:\n",
    "#             x = self.eye_right.origin[0] + self.eye_right.pupil.x\n",
    "#             y = self.eye_right.origin[1] + self.eye_right.pupil.y\n",
    "#             return (x, y)\n",
    "\n",
    "#     def horizontal_ratio(self):\n",
    "#         \"\"\"Returns a number between 0.0 and 1.0 that indicates the\n",
    "#         horizontal direction of the gaze. The extreme right is 0.0,\n",
    "#         the center is 0.5 and the extreme left is 1.0\n",
    "#         \"\"\"\n",
    "#         if self.pupils_located:\n",
    "#             pupil_left = self.eye_left.pupil.x / (self.eye_left.center[0] * 2 - 10)\n",
    "#             pupil_right = self.eye_right.pupil.x / (self.eye_right.center[0] * 2 - 10)\n",
    "#             return (pupil_left + pupil_right) / 2\n",
    "\n",
    "#     def vertical_ratio(self):\n",
    "#         \"\"\"Returns a number between 0.0 and 1.0 that indicates the\n",
    "#         vertical direction of the gaze. The extreme top is 0.0,\n",
    "#         the center is 0.5 and the extreme bottom is 1.0\n",
    "#         \"\"\"\n",
    "#         if self.pupils_located:\n",
    "#             pupil_left = self.eye_left.pupil.y / (self.eye_left.center[1] * 2 - 10)\n",
    "#             pupil_right = self.eye_right.pupil.y / (self.eye_right.center[1] * 2 - 10)\n",
    "#             return (pupil_left + pupil_right) / 2\n",
    "\n",
    "#     def is_right(self):\n",
    "#         \"\"\"Returns true if the user is looking to the right\"\"\"\n",
    "#         if self.pupils_located:\n",
    "#             return self.horizontal_ratio() <= 0.35\n",
    "\n",
    "#     def is_left(self):\n",
    "#         \"\"\"Returns true if the user is looking to the left\"\"\"\n",
    "#         if self.pupils_located:\n",
    "#             return self.horizontal_ratio() >= 0.65\n",
    "\n",
    "#     def is_center(self):\n",
    "#         \"\"\"Returns true if the user is looking to the center\"\"\"\n",
    "#         if self.pupils_located:\n",
    "#             return self.is_right() is not True and self.is_left() is not True\n",
    "\n",
    "#     def is_blinking(self):\n",
    "#         \"\"\"Returns true if the user closes his eyes\"\"\"\n",
    "#         if self.pupils_located:\n",
    "#             blinking_ratio = (self.eye_left.blinking + self.eye_right.blinking) / 2\n",
    "#             return blinking_ratio > 3.8\n",
    "\n",
    "#     def annotated_frame(self):\n",
    "#         \"\"\"Returns the main frame with pupils highlighted\"\"\"\n",
    "#         frame = self.frame.copy()\n",
    "\n",
    "#         if self.pupils_located:\n",
    "#             color = (0, 255, 0)\n",
    "#             x_left, y_left = self.pupil_left_coords()\n",
    "#             x_right, y_right = self.pupil_right_coords()\n",
    "#             cv2.line(frame, (x_left - 5, y_left), (x_left + 5, y_left), color)\n",
    "#             cv2.line(frame, (x_left, y_left - 5), (x_left, y_left + 5), color)\n",
    "#             cv2.line(frame, (x_right - 5, y_right), (x_right + 5, y_right), color)\n",
    "#             cv2.line(frame, (x_right, y_right - 5), (x_right, y_right + 5), color)\n",
    "\n",
    "#         return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "692e2af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T10:59:57.776369Z",
     "start_time": "2022-05-24T10:59:57.759783Z"
    }
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "\n",
    "# class Eye(object):\n",
    "#     \"\"\"\n",
    "#     This class creates a new frame to isolate the eye and\n",
    "#     initiates the pupil detection.\n",
    "#     \"\"\"\n",
    "\n",
    "#     LEFT_EYE_POINTS = [36, 37, 38, 39, 40, 41]\n",
    "#     RIGHT_EYE_POINTS = [42, 43, 44, 45, 46, 47]\n",
    "\n",
    "#     def __init__(self, original_frame, landmarks, side, calibration):\n",
    "#         self.frame = None\n",
    "#         self.origin = None\n",
    "#         self.center = None\n",
    "#         self.pupil = None\n",
    "#         self.landmark_points = None\n",
    "\n",
    "#         self._analyze(original_frame, landmarks, side, calibration)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _middle_point(p1, p2):\n",
    "#         \"\"\"Returns the middle point (x,y) between two points\n",
    "\n",
    "#         Arguments:\n",
    "#             p1 (dlib.point): First point\n",
    "#             p2 (dlib.point): Second point\n",
    "#         \"\"\"\n",
    "#         x = int((p1.x + p2.x) / 2)\n",
    "#         y = int((p1.y + p2.y) / 2)\n",
    "#         return (x, y)\n",
    "\n",
    "#     def _isolate(self, frame, landmarks, points):\n",
    "#         \"\"\"Isolate an eye, to have a frame without other part of the face.\n",
    "\n",
    "#         Arguments:\n",
    "#             frame (numpy.ndarray): Frame containing the face\n",
    "#             landmarks (dlib.full_object_detection): Facial landmarks for the face region\n",
    "#             points (list): Points of an eye (from the 68 Multi-PIE landmarks)\n",
    "#         \"\"\"\n",
    "#         region = np.array([(landmarks.part(point).x, landmarks.part(point).y) for point in points])\n",
    "#         region = region.astype(np.int32)\n",
    "#         self.landmark_points = region\n",
    "\n",
    "#         # Applying a mask to get only the eye\n",
    "#         height, width = frame.shape[:2]\n",
    "#         black_frame = np.zeros((height, width), np.uint8)\n",
    "#         mask = np.full((height, width), 255, np.uint8)\n",
    "#         cv2.fillPoly(mask, [region], (0, 0, 0))\n",
    "#         eye = cv2.bitwise_not(black_frame, frame.copy(), mask=mask)\n",
    "\n",
    "#         # Cropping on the eye\n",
    "#         margin = 5\n",
    "#         min_x = np.min(region[:, 0]) - margin\n",
    "#         max_x = np.max(region[:, 0]) + margin\n",
    "#         min_y = np.min(region[:, 1]) - margin\n",
    "#         max_y = np.max(region[:, 1]) + margin\n",
    "\n",
    "#         self.frame = eye[min_y:max_y, min_x:max_x]\n",
    "#         self.origin = (min_x, min_y)\n",
    "\n",
    "#         height, width = self.frame.shape[:2]\n",
    "#         self.center = (width / 2, height / 2)\n",
    "\n",
    "#     def _blinking_ratio(self, landmarks, points):\n",
    "#         \"\"\"Calculates a ratio that can indicate whether an eye is closed or not.\n",
    "#         It's the division of the width of the eye, by its height.\n",
    "\n",
    "#         Arguments:\n",
    "#             landmarks (dlib.full_object_detection): Facial landmarks for the face region\n",
    "#             points (list): Points of an eye (from the 68 Multi-PIE landmarks)\n",
    "\n",
    "#         Returns:\n",
    "#             The computed ratio\n",
    "#         \"\"\"\n",
    "#         left = (landmarks.part(points[0]).x, landmarks.part(points[0]).y)\n",
    "#         right = (landmarks.part(points[3]).x, landmarks.part(points[3]).y)\n",
    "#         top = self._middle_point(landmarks.part(points[1]), landmarks.part(points[2]))\n",
    "#         bottom = self._middle_point(landmarks.part(points[5]), landmarks.part(points[4]))\n",
    "\n",
    "#         eye_width = math.hypot((left[0] - right[0]), (left[1] - right[1]))\n",
    "#         eye_height = math.hypot((top[0] - bottom[0]), (top[1] - bottom[1]))\n",
    "\n",
    "#         try:\n",
    "#             ratio = eye_width / eye_height\n",
    "#         except ZeroDivisionError:\n",
    "#             ratio = None\n",
    "\n",
    "#         return ratio\n",
    "\n",
    "#     def _analyze(self, original_frame, landmarks, side, calibration):\n",
    "#         \"\"\"Detects and isolates the eye in a new frame, sends data to the calibration\n",
    "#         and initializes Pupil object.\n",
    "\n",
    "#         Arguments:\n",
    "#             original_frame (numpy.ndarray): Frame passed by the user\n",
    "#             landmarks (dlib.full_object_detection): Facial landmarks for the face region\n",
    "#             side: Indicates whether it's the left eye (0) or the right eye (1)\n",
    "#             calibration (calibration.Calibration): Manages the binarization threshold value\n",
    "#         \"\"\"\n",
    "#         if side == 0:\n",
    "#             points = self.LEFT_EYE_POINTS\n",
    "#         elif side == 1:\n",
    "#             points = self.RIGHT_EYE_POINTS\n",
    "#         else:\n",
    "#             return\n",
    "\n",
    "#         self.blinking = self._blinking_ratio(landmarks, points)\n",
    "#         self._isolate(original_frame, landmarks, points)\n",
    "\n",
    "#         if not calibration.is_complete():\n",
    "#             calibration.evaluate(self.frame, side)\n",
    "\n",
    "#         threshold = calibration.threshold(side)\n",
    "#         self.pupil = Pupil(self.frame, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93c7706a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T11:00:02.972223Z",
     "start_time": "2022-05-24T11:00:02.956802Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "\n",
    "# class Pupil(object):\n",
    "#     \"\"\"\n",
    "#     This class detects the iris of an eye and estimates\n",
    "#     the position of the pupil\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, eye_frame, threshold):\n",
    "#         self.iris_frame = None\n",
    "#         self.threshold = threshold\n",
    "#         self.x = None\n",
    "#         self.y = None\n",
    "\n",
    "#         self.detect_iris(eye_frame)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def image_processing(eye_frame, threshold):\n",
    "#         \"\"\"Performs operations on the eye frame to isolate the iris\n",
    "\n",
    "#         Arguments:\n",
    "#             eye_frame (numpy.ndarray): Frame containing an eye and nothing else\n",
    "#             threshold (int): Threshold value used to binarize the eye frame\n",
    "\n",
    "#         Returns:\n",
    "#             A frame with a single element representing the iris\n",
    "#         \"\"\"\n",
    "#         kernel = np.ones((3, 3), np.uint8)\n",
    "#         new_frame = cv2.bilateralFilter(eye_frame, 10, 15, 15)\n",
    "#         new_frame = cv2.erode(new_frame, kernel, iterations=3)\n",
    "#         new_frame = cv2.threshold(new_frame, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "#         return new_frame\n",
    "\n",
    "#     def detect_iris(self, eye_frame):\n",
    "#         \"\"\"Detects the iris and estimates the position of the iris by\n",
    "#         calculating the centroid.\n",
    "\n",
    "#         Arguments:\n",
    "#             eye_frame (numpy.ndarray): Frame containing an eye and nothing else\n",
    "#         \"\"\"\n",
    "#         self.iris_frame = self.image_processing(eye_frame, self.threshold)\n",
    "\n",
    "#         contours, _ = cv2.findContours(self.iris_frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[-2:]\n",
    "#         contours = sorted(contours, key=cv2.contourArea)\n",
    "\n",
    "#         try:\n",
    "#             moments = cv2.moments(contours[-2])\n",
    "#             self.x = int(moments['m10'] / moments['m00'])\n",
    "#             self.y = int(moments['m01'] / moments['m00'])\n",
    "#         except (IndexError, ZeroDivisionError):\n",
    "#             pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b111591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T11:00:06.482756Z",
     "start_time": "2022-05-24T11:00:06.472038Z"
    }
   },
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "# import cv2\n",
    "\n",
    "\n",
    "# class Calibration(object):\n",
    "#     \"\"\"\n",
    "#     This class calibrates the pupil detection algorithm by finding the\n",
    "#     best binarization threshold value for the person and the webcam.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.nb_frames = 20\n",
    "#         self.thresholds_left = []\n",
    "#         self.thresholds_right = []\n",
    "\n",
    "#     def is_complete(self):\n",
    "#         \"\"\"Returns true if the calibration is completed\"\"\"\n",
    "#         return len(self.thresholds_left) >= self.nb_frames and len(self.thresholds_right) >= self.nb_frames\n",
    "\n",
    "#     def threshold(self, side):\n",
    "#         \"\"\"Returns the threshold value for the given eye.\n",
    "\n",
    "#         Argument:\n",
    "#             side: Indicates whether it's the left eye (0) or the right eye (1)\n",
    "#         \"\"\"\n",
    "#         if side == 0:\n",
    "#             return int(sum(self.thresholds_left) / len(self.thresholds_left))\n",
    "#         elif side == 1:\n",
    "#             return int(sum(self.thresholds_right) / len(self.thresholds_right))\n",
    "\n",
    "#     @staticmethod\n",
    "#     def iris_size(frame):\n",
    "#         \"\"\"Returns the percentage of space that the iris takes up on\n",
    "#         the surface of the eye.\n",
    "\n",
    "#         Argument:\n",
    "#             frame (numpy.ndarray): Binarized iris frame\n",
    "#         \"\"\"\n",
    "#         frame = frame[5:-5, 5:-5]\n",
    "#         height, width = frame.shape[:2]\n",
    "#         nb_pixels = height * width\n",
    "#         nb_blacks = nb_pixels - cv2.countNonZero(frame)\n",
    "#         return nb_blacks / nb_pixels\n",
    "\n",
    "#     @staticmethod\n",
    "#     def find_best_threshold(eye_frame):\n",
    "#         \"\"\"Calculates the optimal threshold to binarize the\n",
    "#         frame for the given eye.\n",
    "\n",
    "#         Argument:\n",
    "#             eye_frame (numpy.ndarray): Frame of the eye to be analyzed\n",
    "#         \"\"\"\n",
    "#         average_iris_size = 0.48\n",
    "#         trials = {}\n",
    "\n",
    "#         for threshold in range(5, 100, 5):\n",
    "#             iris_frame = Pupil.image_processing(eye_frame, threshold)\n",
    "#             trials[threshold] = Calibration.iris_size(iris_frame)\n",
    "\n",
    "#         best_threshold, iris_size = min(trials.items(), key=(lambda p: abs(p[1] - average_iris_size)))\n",
    "#         return best_threshold\n",
    "\n",
    "#     def evaluate(self, eye_frame, side):\n",
    "#         \"\"\"Improves calibration by taking into consideration the\n",
    "#         given image.\n",
    "\n",
    "#         Arguments:\n",
    "#             eye_frame (numpy.ndarray): Frame of the eye\n",
    "#             side: Indicates whether it's the left eye (0) or the right eye (1)\n",
    "#         \"\"\"\n",
    "#         threshold = self.find_best_threshold(eye_frame)\n",
    "\n",
    "#         if side == 0:\n",
    "#             self.thresholds_left.append(threshold)\n",
    "#         elif side == 1:\n",
    "#             self.thresholds_right.append(threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d7e43d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T11:57:27.586336Z",
     "start_time": "2023-02-21T11:57:09.269761Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from math import hypot\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "def midpoint(p1 ,p2):\n",
    "    return int((p1.x + p2.x)/2), int((p1.y + p2.y)/2)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "def get_blinking_ratio(eye_points, facial_landmarks):\n",
    "    left_point = (facial_landmarks.part(eye_points[0]).x, facial_landmarks.part(eye_points[0]).y)\n",
    "    right_point = (facial_landmarks.part(eye_points[3]).x, facial_landmarks.part(eye_points[3]).y)\n",
    "    center_top = midpoint(facial_landmarks.part(eye_points[1]), facial_landmarks.part(eye_points[2]))\n",
    "    center_bottom = midpoint(facial_landmarks.part(eye_points[5]), facial_landmarks.part(eye_points[4]))\n",
    "\n",
    "    hor_line = cv2.line(frame, left_point, right_point, (0, 255, 0), 2)\n",
    "    ver_line = cv2.line(frame, center_top, center_bottom, (0, 255, 0), 2)\n",
    "\n",
    "    hor_line_lenght = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "    ver_line_lenght = hypot((center_top[0] - center_bottom[0]), (center_top[1] - center_bottom[1]))\n",
    "\n",
    "    ratio = hor_line_lenght / ver_line_lenght\n",
    "    return ratio\n",
    "\n",
    "def get_gaze_ratio(eye_points, facial_landmarks):\n",
    "    left_eye_region = np.array([(facial_landmarks.part(eye_points[0]).x, facial_landmarks.part(eye_points[0]).y),\n",
    "                                (facial_landmarks.part(eye_points[1]).x, facial_landmarks.part(eye_points[1]).y),\n",
    "                                (facial_landmarks.part(eye_points[2]).x, facial_landmarks.part(eye_points[2]).y),\n",
    "                                (facial_landmarks.part(eye_points[3]).x, facial_landmarks.part(eye_points[3]).y),\n",
    "                                (facial_landmarks.part(eye_points[4]).x, facial_landmarks.part(eye_points[4]).y),\n",
    "                                (facial_landmarks.part(eye_points[5]).x, facial_landmarks.part(eye_points[5]).y)], np.int32)\n",
    "    cv2.polylines(frame, [left_eye_region], True, (0, 0, 255), 2)\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "    mask = np.zeros((height, width), np.uint8)\n",
    "    cv2.polylines(mask, [left_eye_region], True, 255, 2)\n",
    "    cv2.fillPoly(mask, [left_eye_region], 255)\n",
    "    eye = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "\n",
    "    min_x = np.min(left_eye_region[:, 0])\n",
    "    max_x = np.max(left_eye_region[:, 0])\n",
    "    min_y = np.min(left_eye_region[:, 1])\n",
    "    max_y = np.max(left_eye_region[:, 1])\n",
    "\n",
    "    gray_eye = eye[min_y: max_y, min_x: max_x]\n",
    "    _, threshold_eye = cv2.threshold(gray_eye, 70, 255, cv2.THRESH_BINARY)\n",
    "    height, width = threshold_eye.shape\n",
    "    left_side_threshold = threshold_eye[0: height, 0: int(width / 2)]\n",
    "    left_side_white = cv2.countNonZero(left_side_threshold)\n",
    "\n",
    "    cv2.putText(frame,str(left_side_white),(50,150),font,2,(0,0,255),3)\n",
    "    cv2.putText(frame,str(left_side_white),(50,200),font,2,(0,0,255),3)\n",
    "    \n",
    "    right_side_threshold = threshold_eye[0: height, int(width / 2): width]\n",
    "    right_side_white = cv2.countNonZero(right_side_threshold)\n",
    "    \n",
    "\n",
    "    \n",
    "    if left_side_white == 0:\n",
    "        gaze_ratio = 1\n",
    "    elif right_side_white == 0:\n",
    "        gaze_ratio = 5\n",
    "    else:\n",
    "        gaze_ratio = left_side_white / right_side_white\n",
    "    return gaze_ratio\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    new_frame = np.zeros((500, 500, 3), np.uint8)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        x, y = face.left(), face.top()\n",
    "        x1, y1 = face.right(), face.bottom()\n",
    "        cv2.rectangle(frame, (x, y), (x1, y1), (0, 255, 0), 2)\n",
    "\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Detect blinking\n",
    "        left_eye_ratio = get_blinking_ratio([36, 37, 38, 39, 40, 41], landmarks)\n",
    "        right_eye_ratio = get_blinking_ratio([42, 43, 44, 45, 46, 47], landmarks)\n",
    "        blinking_ratio = (left_eye_ratio + right_eye_ratio) / 2\n",
    "\n",
    "        if blinking_ratio > 5.7:\n",
    "            cv2.putText(frame, \"BLINKING\", (50, 150), font, 7, (255, 0, 0),3)\n",
    "\n",
    "\n",
    "        # Gaze detection\n",
    "        gaze_ratio_left_eye = get_gaze_ratio([36, 37, 38, 39, 40, 41], landmarks)\n",
    "        gaze_ratio_right_eye = get_gaze_ratio([42, 43, 44, 45, 46, 47], landmarks)\n",
    "        gaze_ratio = (gaze_ratio_right_eye + gaze_ratio_left_eye) / 2\n",
    "\n",
    "\n",
    "\n",
    "        if gaze_ratio <= 1:\n",
    "            cv2.putText(frame, \"RIGHT\", (50, 100), font, 2, (0, 0, 255), 3)\n",
    "            new_frame[:] = (0, 0, 255)\n",
    "        elif 1 < gaze_ratio < 1.7:\n",
    "            cv2.putText(frame, \"CENTER\", (50, 100), font, 2, (0, 0, 255), 3)\n",
    "        else:\n",
    "            new_frame[:] = (255, 0, 0)\n",
    "            cv2.putText(frame, \"LEFT\", (50, 100), font, 2, (0, 0, 255), 3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"New frame\", new_frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a205fe20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:02:25.283460Z",
     "start_time": "2023-02-21T12:02:22.765201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\reyad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (23.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "904cf01b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T07:43:31.261931Z",
     "start_time": "2023-02-16T07:43:29.170605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in c:\\users\\reyad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.22.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\reyad\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2485755c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T11:53:43.351973Z",
     "start_time": "2023-02-21T11:53:43.267245Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbc0c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T12:02:39.984210Z",
     "start_time": "2023-02-21T12:02:39.980141Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install dlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
